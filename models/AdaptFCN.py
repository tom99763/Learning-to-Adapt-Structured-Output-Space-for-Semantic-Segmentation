from tensorflow.keras.applications.vgg16 import *
from tensorflow.keras import layers, metrics

class FCN(tf.keras.Model):
  def __init__(self, opt):
    super().__init__()
    self.fcn = self.build_fcn(opt)
    
  def call(self, x, training=False):
    return self.fcn(x, training=training)
    
  def build_fcn(self, opt):
    inputs = Input(shape=(*opt.img_size, 3), name='input')
    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)
    
    # Recovering the feature maps generated by each of the 3 final blocks
    f3 = vgg16.get_layer('block3_pool').output  
    f4 = vgg16.get_layer('block4_pool').output  
    f5 = vgg16.get_layer('block5_pool').output  
    
    # Replacing VGG dense layers by convolutions
    f5_conv1 = layers.Conv2D(filters=4096, kernel_size=7, padding='same',
                      activation='relu')(f5)
    f5_drop1 = layers.Dropout(0.5)(f5_conv1)
    f5_conv2 = layers.Conv2D(filters=4096, kernel_size=1, padding='same',
                      activation='relu')(f5_drop1)
    f5_drop2 = layers.Dropout(0.5)(f5_conv2)
    f5_conv3 = layers.Conv2D(filters=ch_out, kernel_size=1, padding='same',
                      activation=None)(f5_drop2)
    
    #merge feautres & prediction
    f5_conv3_x2 = layers.Conv2DTranspose(filters=opt.num_classes, kernel_size=4, strides=2,
                                use_bias=False, padding='same', activation='relu')(f5)
    f4_conv1 = layers.Conv2D(filters=opt.num_classes, kernel_size=1, padding='same', activation=None)(f4)
    merge1 = tf.add([f4_conv1, f5_conv3_x2])
    merge1_x2 = layers.Conv2DTranspose(filters=opt.num_classes, kernel_size=4, strides=2,
                                use_bias=False, padding='same', activation='relu')(merge1)
    f3_conv1 = layers.Conv2D(filters=opt.num_classes, kernel_size=1, padding='same', activation=None)(f3)
    merge2 = tf.add([f3_conv1, merge1_x2])
    outputs = layers.Conv2DTranspose(filters=opt.num_classes, kernel_size=16, strides=8,
                              padding='same', activation=None)(merge2)
    return tf.keras.Model(inputs=inputs, outputs=outputs)
  
  
class Discriminator(tf.keras.Model):
  def __init__(self, opt):
    super().__init__()
    self.disc = tf.keas.Sequential([
      layers.Conv2D(filters = opt.base, kernel_size =4, strides=2, padding='same'), 
      layers.LeakyReLU(0.2)
    ])
    for i in rane(1, opt.num_downsamples):  
      self.disc.add(layers.Conv2D(filters = opt.base * 2 **i, kernel_size =4, strides=2, padding='same')) 
      self.disc.add(layers.LeakyReLU(0.2))
      
    self.disc.add(layers.Conv2D(filters = opt.base * 2 **i, kernel_size =4, strides=2, padding='same'))
    
  def call(self, x):
    return self.disc(x)
  

class AdaptFCN(tf.keras.Model):
  def __init__(self, opt):
    super().__init__()
    
  def call(self, x):
    return 
  
  @tf.function
  def train_step(self, source, target):
    return 
  
  @tf.function
  def test_step(self, source, target):
    return 
